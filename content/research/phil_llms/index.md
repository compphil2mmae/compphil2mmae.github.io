---
title: Philosophy of, and for LLMs
summary: |2- 
  The success of LLMs is fascinating, puzzling and, of course, worrying. It requires our attention and philosophical reflection.
tags:
  - Computationale Philosophie
  - LLMs
date: '2019-02-01T00:00:00Z'
type: 'project'
authors: 
  - gregor.betz

# Optional external URL for project (replaces project detail page).
# external_link: 'https://debatelab.philosophie.kit.edu/'

image:
  caption: (generated with black-forest-labs/FLUX.1-dev)
  focal_point: Smart

links:
#  - icon: twitter
#    icon_pack: fab
#    name: Follow
#    url: https://twitter.com/georgecushen
url_code: ''
url_pdf: ''
url_slides: ''
url_video: ''

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ''
---

Large langauge models (LLMs), essentially probabilistic next-word prediction machines, show semantically good behavior in a broad range of tasks, effectively mastering difficult reasoning problems, meta-cognitive coordination, social cooperation, and practical decision making.

This fundamental empirical datum is philosophically both fascinating and puzzling.

It is fascinating because many science fiction scenarios that have driven, as thought experiments, philosophical investigations in the past are now becoming reality.

It is puzzling because it is not clear how to interpret the success of LLMs (and the neo-connectionist cognitive science research it has spurned) in terms of our traditional concepts of epistemic agency, rationality, consciousness, and moral personhood.

This ongoing projects rests on the assumptions that

1. any philosophical reflection about LLMs must be based on an up-to-date acquaintance of their abilities
2. mastering the novel GenAI technology, building AI systems and running experiments is highly conducive to clarifying philosophical questions about LLMs
3. the philosophical reflection about LLMs can and should be a valuable contribution to the development of the GenAI technology

So far, we have been focusing on the following questions:

* Can LLMs (learn to) argue? [blog](https://debatelab.github.io/journal/critical-thinking-language-models.html) [blog](https://debatelab.github.io/journal/thinking-aloud.html) [blog](https://debatelab.github.io/journal/fallacies-for-big-bench.html)
* Can LLMs (learn to) analyse and evaluate arguments? [blog](https://debatelab.github.io/journal/deepa2.html) 
* Can we ascribe a coherent set of beliefs to LLMs? [blog](https://debatelab.github.io/journal/doxlm.html)
* Can we use LLM-based multi-agent simulations to advance social epistemology? [blog](https://debatelab.github.io/journal/artificial-deliberating-agents.html) [blog](https://debatelab.github.io/talk/compmodels.html)

You can follow us on [github](https://github.com/debatelab) and [huggingface](https://huggingface.co/DebateLabKIT) to stay updated on our progress.
